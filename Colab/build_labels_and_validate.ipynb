!pip -q install ftfy regex tqdm pandas pillow torch torchvision --index-url https://download.pytorch.org/whl/cpu
!pip -q install git+https://github.com/openai/CLIP.git

import json, pandas as pd
from pathlib import Path

CSV_PATH = '/content/foods.csv'       # upload your foods.csv to Colab first
LABELS_JSON = '/content/labels.json'

df = pd.read_csv(CSV_PATH)
# Build canonical label list from food_name + aliases
labels = set()
for _, row in df.iterrows():
    labels.add(str(row['food_name']).strip().lower())
    if 'aliases' in df.columns and isinstance(row['aliases'], str):
        for a in row['aliases'].split(';'):
            a = a.strip().lower()
            if a:
                labels.add(a)
labels = sorted(labels)
with open(LABELS_JSON, 'w') as f:
    json.dump(labels, f, ensure_ascii=False, indent=2)
print('labels:', len(labels))

import torch, clip
from PIL import Image
import pandas as pd

DEVICE = 'cpu'
model, preprocess = clip.load("ViT-B/32", device=DEVICE)

labels = json.load(open(LABELS_JSON))
text_tokens = clip.tokenize([f"a photo of {t}" for t in labels]).to(DEVICE)
text_features = model.encode_text(text_tokens).float()
text_features /= text_features.norm(dim=-1, keepdim=True)

# Replace with your own image file path in Colab
img_path = '/content/sample_food.jpg'
image = preprocess(Image.open(img_path).convert('RGB')).unsqueeze(0).to(DEVICE)
image_features = model.encode_image(image).float()
image_features /= image_features.norm(dim=-1, keepdim=True)

sims = (100.0 * image_features @ text_features.T).softmax(dim=-1).squeeze(0)
probs, idx = torch.topk(sims, k=5)
for p, i in zip(probs.tolist(), idx.tolist()):
    print(f"{labels[i]}: {p:.3f}")